{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RB892KYG72pM"
   },
   "source": [
    "## Import Necessary Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "11MtHj5S76IS"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import chess\n",
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, GlobalAveragePooling2D, InputLayer\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7jTWTsu373no"
   },
   "source": [
    "## Import Data Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "12tDU9p63219"
   },
   "outputs": [],
   "source": [
    "chess_df = pd.read_csv('2014_09_over_1800_one_2100_chess_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jgxvhgWvCFcv"
   },
   "source": [
    "## Prepare Data Source For Use In Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aTsx1C16324q"
   },
   "outputs": [],
   "source": [
    "# Create separate variables for moves, winner, and move number\n",
    "moves = chess_df['moves']\n",
    "winner = chess_df['winner']\n",
    "move_num = chess_df['move_num']\n",
    "X = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mVVLbpE6327Q",
    "outputId": "2ac943c6-b9bd-4ed3-fe62-564436d415ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check max move number because move numbers need to be removed from moves variable\n",
    "max(move_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IRKKLSwM3296"
   },
   "outputs": [],
   "source": [
    "# Create list of move numbers to be removed. I made it much higher than the max moves to be safe\n",
    "char_list = []\n",
    "for i in range(1,500):\n",
    "    char_list.append(str(i) + '.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "piXeL6fk33Ak"
   },
   "outputs": [],
   "source": [
    "# Below code was borrowed from https://towardsdatascience.com/creating-a-chess-engine-with-deep-learning-b9477ff3ee3d\n",
    "\n",
    "# Matrix formatting function\n",
    "def make_matrix(board): \n",
    "    pgn = board.epd()\n",
    "    foo = []  \n",
    "    pieces = pgn.split(\" \", 1)[0]\n",
    "    rows = pieces.split(\"/\")\n",
    "    for row in rows:\n",
    "        foo2 = []  \n",
    "        for thing in row:\n",
    "            if thing.isdigit():\n",
    "                for i in range(0, int(thing)):\n",
    "                    foo2.append('.')\n",
    "            else:\n",
    "                foo2.append(thing)\n",
    "        foo.append(foo2)\n",
    "    return foo\n",
    "\n",
    "\n",
    "# Translate to correct format using chess dict\n",
    "def translate(matrix,chess_dict):\n",
    "    rows = []\n",
    "    for row in matrix:\n",
    "        terms = []\n",
    "        for term in row:\n",
    "            terms.append(chess_dict[term])\n",
    "        rows.append(terms)\n",
    "    return rows\n",
    "\n",
    "\n",
    "# Chess dictionary needed for function    \n",
    "chess_dict = {\n",
    "    'p' : [1,0,0,0,0,0,0,0,0,0,0,0],\n",
    "    'P' : [0,0,0,0,0,0,1,0,0,0,0,0],\n",
    "    'n' : [0,1,0,0,0,0,0,0,0,0,0,0],\n",
    "    'N' : [0,0,0,0,0,0,0,1,0,0,0,0],\n",
    "    'b' : [0,0,1,0,0,0,0,0,0,0,0,0],\n",
    "    'B' : [0,0,0,0,0,0,0,0,1,0,0,0],\n",
    "    'r' : [0,0,0,1,0,0,0,0,0,0,0,0],\n",
    "    'R' : [0,0,0,0,0,0,0,0,0,1,0,0],\n",
    "    'q' : [0,0,0,0,1,0,0,0,0,0,0,0],\n",
    "    'Q' : [0,0,0,0,0,0,0,0,0,0,1,0],\n",
    "    'k' : [0,0,0,0,0,1,0,0,0,0,0,0],\n",
    "    'K' : [0,0,0,0,0,0,0,0,0,0,0,1],\n",
    "    '.' : [0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0wYS4fwY4YHS",
    "outputId": "339f398c-f87e-4aa0-be49-583418f2162d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2397813, 8, 8, 12)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Below code was borrowed from https://towardsdatascience.com/creating-a-chess-engine-with-deep-learning-b9477ff3ee3d\n",
    "\n",
    "# Transform data set to be used in neural net models\n",
    "for game in moves:\n",
    "    index = list(moves).index(game)\n",
    "    allmoves = game.split()\n",
    "    all_moves = [elem for elem in allmoves if elem not in char_list] \n",
    "    total_moves = len(all_moves)\n",
    "    if winner[index] == 'black':\n",
    "        game_winner = -1\n",
    "    else:\n",
    "        game_winner = 1\n",
    "    board = chess.Board()\n",
    "    for i in range(len(all_moves)):\n",
    "        board.push_san(all_moves[i])\n",
    "        value = game_winner * (i/total_moves)\n",
    "        matrix = make_matrix(board.copy())\n",
    "        rows = translate(matrix,chess_dict)\n",
    "        X.append([rows])\n",
    "        y.append(value)\n",
    "X = np.array(X).reshape(len(X),8,8,12)\n",
    "y = np.array(y)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SePyrV0VYTH4"
   },
   "source": [
    "## Convolutional Neural Network Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hto-QLhq4YJ3",
    "outputId": "cc8a5384-be68-446e-eb2f-4521d22f199b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 8, 8, 8)           872       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 4, 4, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 4, 4, 16)          1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 2, 2, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 2, 2, 32)          4640      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 7,089\n",
      "Trainable params: 7,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "56199/56199 [==============================] - 196s 3ms/step - loss: 0.2711 - val_loss: 0.2650\n",
      "Epoch 2/25\n",
      "56199/56199 [==============================] - 192s 3ms/step - loss: 0.2559 - val_loss: 0.2644\n",
      "Epoch 3/25\n",
      "56199/56199 [==============================] - 206s 4ms/step - loss: 0.2526 - val_loss: 0.2650\n",
      "Epoch 4/25\n",
      "56199/56199 [==============================] - 190s 3ms/step - loss: 0.2509 - val_loss: 0.2669\n",
      "Epoch 5/25\n",
      "56199/56199 [==============================] - 195s 3ms/step - loss: 0.2492 - val_loss: 0.2664\n",
      "Epoch 6/25\n",
      "56199/56199 [==============================] - 196s 3ms/step - loss: 0.2484 - val_loss: 0.2665\n",
      "Epoch 7/25\n",
      "56199/56199 [==============================] - 196s 3ms/step - loss: 0.2470 - val_loss: 0.2670\n",
      "Epoch 8/25\n",
      "56199/56199 [==============================] - 192s 3ms/step - loss: 0.2464 - val_loss: 0.2667\n",
      "Epoch 9/25\n",
      "56199/56199 [==============================] - 204s 4ms/step - loss: 0.2454 - val_loss: 0.2685\n",
      "Epoch 10/25\n",
      "56199/56199 [==============================] - 203s 4ms/step - loss: 0.2450 - val_loss: 0.2704\n",
      "Epoch 11/25\n",
      "56199/56199 [==============================] - 202s 4ms/step - loss: 0.2444 - val_loss: 0.2699\n",
      "Epoch 12/25\n",
      "56199/56199 [==============================] - 203s 4ms/step - loss: 0.2441 - val_loss: 0.2719\n",
      "Epoch 13/25\n",
      "56199/56199 [==============================] - 204s 4ms/step - loss: 0.2439 - val_loss: 0.2715\n",
      "Epoch 14/25\n",
      "56199/56199 [==============================] - 204s 4ms/step - loss: 0.2437 - val_loss: 0.2740\n",
      "Epoch 15/25\n",
      "56199/56199 [==============================] - 199s 4ms/step - loss: 0.2431 - val_loss: 0.2716\n",
      "Epoch 16/25\n",
      "56199/56199 [==============================] - 194s 3ms/step - loss: 0.2427 - val_loss: 0.2719\n",
      "Epoch 17/25\n",
      "56199/56199 [==============================] - 196s 3ms/step - loss: 0.2426 - val_loss: 0.2722\n",
      "Epoch 18/25\n",
      "56199/56199 [==============================] - 197s 4ms/step - loss: 0.2423 - val_loss: 0.2750\n",
      "Epoch 19/25\n",
      "56199/56199 [==============================] - 202s 4ms/step - loss: 0.2418 - val_loss: 0.2716\n",
      "Epoch 20/25\n",
      "56199/56199 [==============================] - 202s 4ms/step - loss: 0.2415 - val_loss: 0.2745\n",
      "Epoch 21/25\n",
      "56199/56199 [==============================] - 199s 4ms/step - loss: 0.2418 - val_loss: 0.2747\n",
      "Epoch 22/25\n",
      "56199/56199 [==============================] - 205s 4ms/step - loss: 0.2420 - val_loss: 0.2715\n",
      "Epoch 23/25\n",
      "51314/56199 [==========================>...] - ETA: 18s - loss: 0.2415"
     ]
    }
   ],
   "source": [
    "# Baseline CNN model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# The input shape is 8,8,12 because it's an 8*8 board with 12 different piece types \n",
    "# (king, queen, bishop, knight, rook, pawn) * 2 for each color\n",
    "model.add(InputLayer(input_shape=(8,8,12)))\n",
    "\n",
    "model.add(Conv2D(filters=8, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(1,activation = 'tanh'))\n",
    "\n",
    "model.compile(loss='mse', optimizer='nadam')\n",
    "\n",
    "model.summary()\n",
    "model.fit(X, y, epochs=25, verbose=1, validation_split=0.25,\n",
    "       callbacks=[\n",
    "           keras.callbacks.ModelCheckpoint(\n",
    "               'models/chessb.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "               save_best_only=True)\n",
    "       ])  # track progress as we fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j-sRyxMQ4YMj",
    "outputId": "6b03e66d-fd58-4f10-b46f-6cc1b7f35c67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 16)          1744      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 32)          4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 2, 2, 64)          18496     \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                780       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 25,673\n",
      "Trainable params: 25,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "56199/56199 [==============================] - 276s 5ms/step - loss: 0.2950 - val_loss: 0.2783\n",
      "Epoch 2/25\n",
      "56199/56199 [==============================] - 280s 5ms/step - loss: 0.2824 - val_loss: 0.2753\n",
      "Epoch 3/25\n",
      "56199/56199 [==============================] - 275s 5ms/step - loss: 0.2811 - val_loss: 0.2765\n",
      "Epoch 4/25\n",
      "56199/56199 [==============================] - 280s 5ms/step - loss: 0.2807 - val_loss: 0.2786\n",
      "Epoch 5/25\n",
      "56199/56199 [==============================] - 288s 5ms/step - loss: 0.2806 - val_loss: 0.2750\n",
      "Epoch 6/25\n",
      "56199/56199 [==============================] - 294s 5ms/step - loss: 0.2794 - val_loss: 0.2764\n",
      "Epoch 7/25\n",
      "56199/56199 [==============================] - 299s 5ms/step - loss: 0.2794 - val_loss: 0.2747\n",
      "Epoch 8/25\n",
      "56199/56199 [==============================] - 286s 5ms/step - loss: 0.2793 - val_loss: 0.2770\n",
      "Epoch 9/25\n",
      "56199/56199 [==============================] - 284s 5ms/step - loss: 0.2795 - val_loss: 0.2747\n",
      "Epoch 10/25\n",
      "56199/56199 [==============================] - 300s 5ms/step - loss: 0.2790 - val_loss: 0.2735\n",
      "Epoch 11/25\n",
      "56199/56199 [==============================] - 303s 5ms/step - loss: 0.2792 - val_loss: 0.2760\n",
      "Epoch 12/25\n",
      "56199/56199 [==============================] - 302s 5ms/step - loss: 0.2789 - val_loss: 0.2747\n",
      "Epoch 13/25\n",
      "56199/56199 [==============================] - 305s 5ms/step - loss: 0.2792 - val_loss: 0.2777\n",
      "Epoch 14/25\n",
      "56199/56199 [==============================] - 296s 5ms/step - loss: 0.2788 - val_loss: 0.2750\n",
      "Epoch 15/25\n",
      "56199/56199 [==============================] - 299s 5ms/step - loss: 0.2790 - val_loss: 0.2760\n",
      "Epoch 16/25\n",
      "56199/56199 [==============================] - 311s 6ms/step - loss: 0.2788 - val_loss: 0.2773\n",
      "Epoch 17/25\n",
      "56199/56199 [==============================] - 306s 5ms/step - loss: 0.2790 - val_loss: 0.2768\n",
      "Epoch 18/25\n",
      "56199/56199 [==============================] - 288s 5ms/step - loss: 0.2789 - val_loss: 0.2740\n",
      "Epoch 19/25\n",
      "56199/56199 [==============================] - 296s 5ms/step - loss: 0.2783 - val_loss: 0.2765\n",
      "Epoch 20/25\n",
      "56199/56199 [==============================] - 312s 6ms/step - loss: 0.2788 - val_loss: 0.2763\n",
      "Epoch 21/25\n",
      "56199/56199 [==============================] - 316s 6ms/step - loss: 0.2784 - val_loss: 0.2753\n",
      "Epoch 22/25\n",
      "56199/56199 [==============================] - 317s 6ms/step - loss: 0.2784 - val_loss: 0.2742\n",
      "Epoch 23/25\n",
      "56199/56199 [==============================] - 315s 6ms/step - loss: 0.2784 - val_loss: 0.2762\n",
      "Epoch 24/25\n",
      "56199/56199 [==============================] - 318s 6ms/step - loss: 0.2787 - val_loss: 0.2740\n",
      "Epoch 25/25\n",
      "56199/56199 [==============================] - 303s 5ms/step - loss: 0.2781 - val_loss: 0.2749\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1e7aadf650>"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline model with three dropout layers added and convolutional filters increased\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# The input shape is 8,8,12 because it's an 8*8 board with 12 different piece types \n",
    "# (king, queen, bishop, knight, rook, pawn) * 2 for each color\n",
    "model.add(InputLayer(input_shape=(8,8,12)))\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(1,activation = 'tanh'))\n",
    "\n",
    "model.compile(loss='mse', optimizer='nadam')\n",
    "\n",
    "model.summary()\n",
    "model.fit(X, y, epochs=25, verbose=1, validation_split=0.25,\n",
    "       callbacks=[\n",
    "           keras.callbacks.ModelCheckpoint(\n",
    "               'models/chessb2.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "               save_best_only=True)\n",
    "       ])  # track progress as we fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FFyI1RZV4YPJ",
    "outputId": "da47a603-8b5f-40b6-d9b8-8dfe9affd5b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 8, 8, 8)           872       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 8)           0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 4, 4, 16)          1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 2, 2, 16)          0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 2, 2, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 2, 2, 32)          4640      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_3 ( (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 7,089\n",
      "Trainable params: 7,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "56199/56199 [==============================] - 191s 3ms/step - loss: 0.3090 - val_loss: 0.2930\n",
      "Epoch 2/25\n",
      "56199/56199 [==============================] - 188s 3ms/step - loss: 0.2944 - val_loss: 0.2948\n",
      "Epoch 3/25\n",
      "56199/56199 [==============================] - 193s 3ms/step - loss: 0.2942 - val_loss: 0.2889\n",
      "Epoch 4/25\n",
      "56199/56199 [==============================] - 188s 3ms/step - loss: 0.2936 - val_loss: 0.2957\n",
      "Epoch 5/25\n",
      "56199/56199 [==============================] - 187s 3ms/step - loss: 0.2932 - val_loss: 0.2950\n",
      "Epoch 6/25\n",
      "56199/56199 [==============================] - 197s 4ms/step - loss: 0.2926 - val_loss: 0.2920\n",
      "Epoch 7/25\n",
      "56199/56199 [==============================] - 193s 3ms/step - loss: 0.2925 - val_loss: 0.2912\n",
      "Epoch 8/25\n",
      "56199/56199 [==============================] - 191s 3ms/step - loss: 0.2929 - val_loss: 0.2894\n",
      "Epoch 9/25\n",
      "56199/56199 [==============================] - 193s 3ms/step - loss: 0.2926 - val_loss: 0.2932\n",
      "Epoch 10/25\n",
      "56199/56199 [==============================] - 198s 4ms/step - loss: 0.2923 - val_loss: 0.2955\n",
      "Epoch 11/25\n",
      "56199/56199 [==============================] - 195s 3ms/step - loss: 0.2921 - val_loss: 0.2897\n",
      "Epoch 12/25\n",
      "56199/56199 [==============================] - 190s 3ms/step - loss: 0.2920 - val_loss: 0.2923\n",
      "Epoch 13/25\n",
      "56199/56199 [==============================] - 188s 3ms/step - loss: 0.2923 - val_loss: 0.2868\n",
      "Epoch 14/25\n",
      "56199/56199 [==============================] - 192s 3ms/step - loss: 0.2930 - val_loss: 0.2876\n",
      "Epoch 15/25\n",
      "56199/56199 [==============================] - 190s 3ms/step - loss: 0.2920 - val_loss: 0.2924\n",
      "Epoch 16/25\n",
      "56199/56199 [==============================] - 190s 3ms/step - loss: 0.2921 - val_loss: 0.2898\n",
      "Epoch 17/25\n",
      "56199/56199 [==============================] - 189s 3ms/step - loss: 0.2920 - val_loss: 0.2909\n",
      "Epoch 18/25\n",
      "56199/56199 [==============================] - 191s 3ms/step - loss: 0.2924 - val_loss: 0.2898\n",
      "Epoch 19/25\n",
      "56199/56199 [==============================] - 193s 3ms/step - loss: 0.2918 - val_loss: 0.2905\n",
      "Epoch 20/25\n",
      "56199/56199 [==============================] - 187s 3ms/step - loss: 0.2921 - val_loss: 0.2867\n",
      "Epoch 21/25\n",
      "56199/56199 [==============================] - 188s 3ms/step - loss: 0.2921 - val_loss: 0.2921\n",
      "Epoch 22/25\n",
      "56199/56199 [==============================] - 192s 3ms/step - loss: 0.2920 - val_loss: 0.2896\n",
      "Epoch 23/25\n",
      "56199/56199 [==============================] - 194s 3ms/step - loss: 0.2918 - val_loss: 0.2889\n",
      "Epoch 24/25\n",
      "56199/56199 [==============================] - 187s 3ms/step - loss: 0.2916 - val_loss: 0.2889\n",
      "Epoch 25/25\n",
      "56199/56199 [==============================] - 192s 3ms/step - loss: 0.2924 - val_loss: 0.2888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0162fda250>"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline model with three dropout layers added\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# The input shape is 8,8,12 because it's an 8*8 board with 12 different piece types \n",
    "# (king, queen, bishop, knight, rook, pawn) * 2 for each color\n",
    "model.add(InputLayer(input_shape=(8,8,12)))\n",
    "\n",
    "model.add(Conv2D(filters=8, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(1,activation = 'tanh'))\n",
    "\n",
    "model.compile(loss='mse', optimizer='nadam')\n",
    "\n",
    "model.summary()\n",
    "model.fit(X, y, epochs=25, verbose=1, validation_split=0.25,\n",
    "       callbacks=[\n",
    "           keras.callbacks.ModelCheckpoint(\n",
    "               'models/chessb3.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "               save_best_only=True)\n",
    "       ])  # track progress as we fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5iNFfzWD4YR4",
    "outputId": "fbce09ca-6979-4fe7-b0d1-83e002efae24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 8)           872       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 16)          1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 2, 2, 32)          4640      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 7,089\n",
      "Trainable params: 7,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "56199/56199 [==============================] - 167s 3ms/step - loss: 0.2763 - val_loss: 0.2672\n",
      "Epoch 2/25\n",
      "56199/56199 [==============================] - 175s 3ms/step - loss: 0.2602 - val_loss: 0.2689\n",
      "Epoch 3/25\n",
      "56199/56199 [==============================] - 182s 3ms/step - loss: 0.2584 - val_loss: 0.2697\n",
      "Epoch 4/25\n",
      "56199/56199 [==============================] - 189s 3ms/step - loss: 0.2566 - val_loss: 0.2702\n",
      "Epoch 5/25\n",
      "56199/56199 [==============================] - 171s 3ms/step - loss: 0.2559 - val_loss: 0.2703\n",
      "Epoch 6/25\n",
      "56199/56199 [==============================] - 171s 3ms/step - loss: 0.2553 - val_loss: 0.2712\n",
      "Epoch 7/25\n",
      "56199/56199 [==============================] - 173s 3ms/step - loss: 0.2548 - val_loss: 0.2705\n",
      "Epoch 8/25\n",
      "56199/56199 [==============================] - 185s 3ms/step - loss: 0.2539 - val_loss: 0.2736\n",
      "Epoch 9/25\n",
      "56199/56199 [==============================] - 184s 3ms/step - loss: 0.2542 - val_loss: 0.2705\n",
      "Epoch 10/25\n",
      "56199/56199 [==============================] - 183s 3ms/step - loss: 0.2531 - val_loss: 0.2665\n",
      "Epoch 11/25\n",
      "56199/56199 [==============================] - 183s 3ms/step - loss: 0.2529 - val_loss: 0.2657\n",
      "Epoch 12/25\n",
      "56199/56199 [==============================] - 183s 3ms/step - loss: 0.2534 - val_loss: 0.2680\n",
      "Epoch 13/25\n",
      "56199/56199 [==============================] - 184s 3ms/step - loss: 0.2532 - val_loss: 0.2661\n",
      "Epoch 14/25\n",
      "56199/56199 [==============================] - 184s 3ms/step - loss: 0.2535 - val_loss: 0.2652\n",
      "Epoch 15/25\n",
      "56199/56199 [==============================] - 181s 3ms/step - loss: 0.2529 - val_loss: 0.2653\n",
      "Epoch 16/25\n",
      "56199/56199 [==============================] - 178s 3ms/step - loss: 0.2526 - val_loss: 0.2654\n",
      "Epoch 17/25\n",
      "56199/56199 [==============================] - 179s 3ms/step - loss: 0.2527 - val_loss: 0.2667\n",
      "Epoch 18/25\n",
      "56199/56199 [==============================] - 183s 3ms/step - loss: 0.2525 - val_loss: 0.2674\n",
      "Epoch 19/25\n",
      "56199/56199 [==============================] - 182s 3ms/step - loss: 0.2520 - val_loss: 0.2673\n",
      "Epoch 20/25\n",
      "56199/56199 [==============================] - 183s 3ms/step - loss: 0.2521 - val_loss: 0.2677\n",
      "Epoch 21/25\n",
      "56199/56199 [==============================] - 183s 3ms/step - loss: 0.2518 - val_loss: 0.2655\n",
      "Epoch 22/25\n",
      "56199/56199 [==============================] - 184s 3ms/step - loss: 0.2518 - val_loss: 0.2666\n",
      "Epoch 23/25\n",
      "56199/56199 [==============================] - 183s 3ms/step - loss: 0.2516 - val_loss: 0.2664\n",
      "Epoch 24/25\n",
      "56199/56199 [==============================] - 186s 3ms/step - loss: 0.2513 - val_loss: 0.2678\n",
      "Epoch 25/25\n",
      "56199/56199 [==============================] - 196s 3ms/step - loss: 0.2513 - val_loss: 0.2653\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f01666913d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline model with one dropout layer added\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# The input shape is 8,8,12 because it's an 8*8 board with 12 different piece types \n",
    "# (king, queen, bishop, knight, rook, pawn) * 2 for each color\n",
    "model.add(InputLayer(input_shape=(8,8,12)))\n",
    "\n",
    "model.add(Conv2D(filters=8, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(1,activation = 'tanh'))\n",
    "\n",
    "model.compile(loss='mse', optimizer='nadam')\n",
    "\n",
    "model.summary()\n",
    "model.fit(X, y, epochs=25, verbose=1, validation_split=0.25,\n",
    "       callbacks=[\n",
    "           keras.callbacks.ModelCheckpoint(\n",
    "               'models/chessb4.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "               save_best_only=True)\n",
    "       ])  # track progress as we fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lqEYviZ340B9",
    "outputId": "40a41933-2034-4745-b5f5-f28f5bcb0968"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 8)           872       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 8)           0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 4, 4, 16)          1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 2, 2, 16)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2, 2, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 2, 2, 32)          4640      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 7,089\n",
      "Trainable params: 7,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "56199/56199 [==============================] - 183s 3ms/step - loss: 0.2988 - val_loss: 0.2798\n",
      "Epoch 2/25\n",
      "56199/56199 [==============================] - 175s 3ms/step - loss: 0.2874 - val_loss: 0.2799\n",
      "Epoch 3/25\n",
      "56199/56199 [==============================] - 177s 3ms/step - loss: 0.2864 - val_loss: 0.2799\n",
      "Epoch 4/25\n",
      "56199/56199 [==============================] - 181s 3ms/step - loss: 0.2857 - val_loss: 0.2780\n",
      "Epoch 5/25\n",
      "56199/56199 [==============================] - 178s 3ms/step - loss: 0.2852 - val_loss: 0.2785\n",
      "Epoch 6/25\n",
      "56199/56199 [==============================] - 179s 3ms/step - loss: 0.2850 - val_loss: 0.2787\n",
      "Epoch 7/25\n",
      "56199/56199 [==============================] - 184s 3ms/step - loss: 0.2843 - val_loss: 0.2767\n",
      "Epoch 8/25\n",
      "56199/56199 [==============================] - 183s 3ms/step - loss: 0.2850 - val_loss: 0.2797\n",
      "Epoch 9/25\n",
      "56199/56199 [==============================] - 184s 3ms/step - loss: 0.2843 - val_loss: 0.2773\n",
      "Epoch 10/25\n",
      "56199/56199 [==============================] - 181s 3ms/step - loss: 0.2847 - val_loss: 0.2781\n",
      "Epoch 11/25\n",
      "56199/56199 [==============================] - 181s 3ms/step - loss: 0.2842 - val_loss: 0.2788\n",
      "Epoch 12/25\n",
      "56199/56199 [==============================] - 183s 3ms/step - loss: 0.2844 - val_loss: 0.2774\n",
      "Epoch 13/25\n",
      "56199/56199 [==============================] - 183s 3ms/step - loss: 0.2843 - val_loss: 0.2774\n",
      "Epoch 14/25\n",
      "56199/56199 [==============================] - 185s 3ms/step - loss: 0.2836 - val_loss: 0.2765\n",
      "Epoch 15/25\n",
      "56199/56199 [==============================] - 184s 3ms/step - loss: 0.2842 - val_loss: 0.2774\n",
      "Epoch 16/25\n",
      "56199/56199 [==============================] - 189s 3ms/step - loss: 0.2839 - val_loss: 0.2797\n",
      "Epoch 17/25\n",
      "56199/56199 [==============================] - 192s 3ms/step - loss: 0.2840 - val_loss: 0.2775\n",
      "Epoch 18/25\n",
      "56199/56199 [==============================] - 186s 3ms/step - loss: 0.2839 - val_loss: 0.2792\n",
      "Epoch 19/25\n",
      "56199/56199 [==============================] - 183s 3ms/step - loss: 0.2839 - val_loss: 0.2780\n",
      "Epoch 20/25\n",
      "56199/56199 [==============================] - 183s 3ms/step - loss: 0.2841 - val_loss: 0.2779\n",
      "Epoch 21/25\n",
      "56199/56199 [==============================] - 182s 3ms/step - loss: 0.2840 - val_loss: 0.2771\n",
      "Epoch 22/25\n",
      "56199/56199 [==============================] - 184s 3ms/step - loss: 0.2838 - val_loss: 0.2781\n",
      "Epoch 23/25\n",
      "56199/56199 [==============================] - 184s 3ms/step - loss: 0.2838 - val_loss: 0.2805\n",
      "Epoch 24/25\n",
      "56199/56199 [==============================] - 186s 3ms/step - loss: 0.2838 - val_loss: 0.2810\n",
      "Epoch 25/25\n",
      "56199/56199 [==============================] - 189s 3ms/step - loss: 0.2838 - val_loss: 0.2795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0163aac4d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline model with two dropout layers added\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# The input shape is 8,8,12 because it's an 8*8 board with 12 different piece types \n",
    "# (king, queen, bishop, knight, rook, pawn) * 2 for each color\n",
    "model.add(InputLayer(input_shape=(8,8,12)))\n",
    "\n",
    "model.add(Conv2D(filters=8, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(1,activation = 'tanh'))\n",
    "\n",
    "model.compile(loss='mse', optimizer='nadam')\n",
    "\n",
    "model.summary()\n",
    "model.fit(X, y, epochs=25, verbose=1, validation_split=0.25,\n",
    "       callbacks=[\n",
    "           keras.callbacks.ModelCheckpoint(\n",
    "               'models/chessb5.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "               save_best_only=True)\n",
    "       ])  # track progress as we fit"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Convolutional Neural Network Models.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
